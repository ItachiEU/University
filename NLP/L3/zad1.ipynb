{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit15739fc702ac4a39a51b6a8572e59d06",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import random\n",
    "import statistics as st\n",
    "import itertools as iter\n",
    "\n",
    "learningSet = []\n",
    "validationSet = []\n",
    "\n",
    "with open('../../NLP_Resources/polish_corpora.txt') as f:\n",
    "    lineCounter = 0\n",
    "    learningSetSize = 1000000\n",
    "    validationSetSize = 200000\n",
    "    for line in f:\n",
    "        if lineCounter < learningSetSize:\n",
    "            learningSet.append(line)\n",
    "        else:\n",
    "            validationSet.append(line)\n",
    "\n",
    "        lineCounter += 1\n",
    "        if lineCounter > (learningSetSize + validationSetSize):\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletePolishCharacters(word):\n",
    "    polishToEnglish = {'ą': 'a', 'ć': 'c', 'ę': 'e', 'ł': 'l', 'ń': 'n', 'ó': 'o', 'ś': 's', 'ż': 'z', 'ź': 'z'}\n",
    "\n",
    "    word = word.lower()\n",
    "\n",
    "    resultWord = ''\n",
    "    \n",
    "    for character in word:\n",
    "        resultWord += polishToEnglish.get(character, character)\n",
    "\n",
    "    return resultWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setting up most of the data structures that I am going to need\n",
    "\n",
    "wordUpperVsLower = defaultdict(lambda: [0,0]) # upper, lower\n",
    "cleanReverseOptions = defaultdict(lambda: defaultdict(int)) # dict of words -> probability\n",
    "bigramUpperVsLower = defaultdict(lambda: [0,0]) # upper, lower\n",
    "bigramSuffix = defaultdict(int)\n",
    "\n",
    "for line in learningSet:\n",
    "    line = line.split()\n",
    "    wordIndexInLine = 0\n",
    "    \n",
    "    #unigram statistics\n",
    "    for word in line:\n",
    "        wordCleaned = deletePolishCharacters(word)\n",
    "\n",
    "        if wordCleaned == 'sie':\n",
    "            cleanReverseOptions[wordCleaned]['się'] +=1\n",
    "        else:\n",
    "            cleanReverseOptions[wordCleaned][word.lower()] += 1\n",
    "        \n",
    "\n",
    "        #capital letters\n",
    "        if word[0].islower():\n",
    "            wordUpperVsLower[wordCleaned][1] +=1\n",
    "        if word[0].isupper() and wordIndexInLine != 0:\n",
    "            wordUpperVsLower[wordCleaned][0] +=1\n",
    "\n",
    "\n",
    "        wordIndexInLine += 1\n",
    "        \n",
    "    #bigram statistics\n",
    "    for i in range(len(line)-1):\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        word1 = line[i]\n",
    "        word2 = line[i+1]\n",
    "\n",
    "        hash = word1.lower()[-3:] + '#' + word2.lower()[-3:]\n",
    "\n",
    "        bigramSuffix[hash] +=1\n",
    "        \n",
    "        word1Cleaned = deletePolishCharacters(word1)\n",
    "        word2Cleaned = deletePolishCharacters(word2)\n",
    "        \n",
    "        hash = word1Cleaned + '#' + word2Cleaned\n",
    "\n",
    "        if word1[0].isupper() and word2[0].isupper():\n",
    "            bigramUpperVsLower[hash][0] += 1\n",
    "        else:\n",
    "            bigramUpperVsLower[hash][1] += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in wordUpperVsLower:\n",
    "    a, b = wordUpperVsLower[key]\n",
    "    if a < b and a / b < 0.07:\n",
    "        wordUpperVsLower[key][0] = 0\n",
    "\n",
    "for key in cleanReverseOptions:\n",
    "    options = []\n",
    "    for word in cleanReverseOptions[key]:\n",
    "        if cleanReverseOptions[key][word] > 0:\n",
    "            options.append((cleanReverseOptions[key][word], word))\n",
    "    options = sorted(options, reverse=True)\n",
    "    if len(options) == 0:\n",
    "        continue\n",
    "    maks = options[0][0]\n",
    "    for option in options:\n",
    "        if option[0]/maks < 0.03:\n",
    "            cleanReverseOptions[key].pop(option[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../NLP_Resources/poleval_2grams.txt') as f:\n",
    "    for line in f:\n",
    "        v, w1, w2 = line.split()\n",
    "        w1Cleaned = deletePolishCharacters(w1)\n",
    "        w2Cleaned = deletePolishCharacters(w2)\n",
    "\n",
    "        sz = len(cleanReverseOptions[w1Cleaned])\n",
    "        if sz == 0:\n",
    "            cleanReverseOptions[w1Cleaned][w1] = 1\n",
    "        if sz <= 3:\n",
    "            temp = 0\n",
    "            for key in cleanReverseOptions[w1Cleaned]:\n",
    "                    temp += cleanReverseOptions[w1Cleaned][key]\n",
    "            if temp == 0:\n",
    "                cleanReverseOptions[w1Cleaned][w1] = 1\n",
    "        \n",
    "        sz = len(cleanReverseOptions[w2Cleaned])\n",
    "        if sz == 0:\n",
    "            cleanReverseOptions[w2Cleaned][w2] = 1\n",
    "        if sz <= 3:\n",
    "            temp = 0\n",
    "            for key in cleanReverseOptions[w2Cleaned]:\n",
    "                    temp += cleanReverseOptions[w2Cleaned][key]\n",
    "            if temp == 0:\n",
    "                cleanReverseOptions[w2Cleaned][w2] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectWordFromUnigrams(wordCleaned):\n",
    "    potentialWords = []\n",
    "    probabilities = []\n",
    "    for candidate in cleanReverseOptions[wordCleaned]:\n",
    "        potentialWords.append(candidate)\n",
    "        probabilities.append(cleanReverseOptions[wordCleaned][candidate])\n",
    "\n",
    "    if len(potentialWords) < 1:\n",
    "        return wordCleaned\n",
    "    probabilities = np.array(probabilities)\n",
    "    potentialWords = np.array(potentialWords)\n",
    "    sum = np.sum(probabilities)\n",
    "\n",
    "    selectedWord = np.random.choice(potentialWords, p= probabilities/sum)\n",
    "    return selectedWord\n",
    "\n",
    "def capitalizeUnigram(selectedWord):\n",
    "    probs = np.array(wordUpperVsLower.get(selectedWord, [0,0]))\n",
    "    options = np.array([True, False])\n",
    "    sum = np.sum(probs)\n",
    "    if sum == 0:\n",
    "        return False\n",
    "    decision = np.random.choice(options, p = probs/sum)\n",
    "    return decision\n",
    "    \n",
    "def selectWordsFromBigrams(word1Cleaned, word2Cleaned):\n",
    "    options1, options2 = ([],[])\n",
    "    \n",
    "    for word in cleanReverseOptions[word1Cleaned]:\n",
    "        options1.append(word)\n",
    "    \n",
    "    for word in cleanReverseOptions[word2Cleaned]:\n",
    "        options2.append(word)\n",
    "\n",
    "    if len(cleanReverseOptions[word2Cleaned]) == 0:\n",
    "        options2.append(word2Cleaned)\n",
    "\n",
    "    resultCandidates = []\n",
    "    \n",
    "    for word1 in options1:\n",
    "        for word2 in options2:\n",
    "            h = word1[-3:] + '#' + word2[-3:]\n",
    "            resultCandidates.append((bigramSuffix[h], (word1, word2)))\n",
    "    \n",
    "    resultCandidates = sorted(resultCandidates, reverse = True)\n",
    "\n",
    "    if len(resultCandidates) == 0:\n",
    "        return ('-1', '-1')\n",
    "        #return (word1Cleaned, word2Cleaned)\n",
    "\n",
    "    return resultCandidates[0][1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "score = 0\n",
    "wordCount = 0\n",
    "correctWordsCount = 0\n",
    "correctWordsCountWithCapitalization = 0\n",
    "\n",
    "for line in validationSet:\n",
    "    line = line.split()\n",
    "    resultLine = []\n",
    "    skip = False\n",
    "\n",
    "    for i in range(len(line)):\n",
    "        word = line[i]\n",
    "        wordCleaned = deletePolishCharacters(word)\n",
    "        if i == 0:\n",
    "            selectedWord = selectWordFromUnigrams(wordCleaned)\n",
    "        else:\n",
    "            previousWord = deletePolishCharacters(resultLine[i-1])\n",
    "            word2 = wordCleaned\n",
    "\n",
    "            selectedWord = selectWordsFromBigrams(previousWord, word2)[1]\n",
    "            if selectedWord == '-1':\n",
    "                selectedWord = selectWordFromUnigrams(wordCleaned)\n",
    "\n",
    "            # print(selectedWord)\n",
    "        \n",
    "        resultLine.append(selectedWord)\n",
    "\n",
    "\n",
    "    #Handle capital letters\n",
    "    for i in range(len(line)):\n",
    "        if skip:\n",
    "            skip = False\n",
    "            continue\n",
    "\n",
    "        word1 = resultLine[i]\n",
    "        word1Cleaned = deletePolishCharacters(word1)\n",
    "        if i != len(line)-1:\n",
    "            #handle bigrams\n",
    "            word2 = resultLine[i+1]\n",
    "\n",
    "            hash = word1Cleaned + '#' + deletePolishCharacters(word2)\n",
    "\n",
    "            if bigramUpperVsLower[hash][1] > 0 and bigramUpperVsLower[hash][1] == 0:\n",
    "                resultLine[i] = resultLine[i].capitalize()\n",
    "                resultLine[i+1] = resultLine[i+1].capitalize()\n",
    "                skip = True\n",
    "                continue\n",
    "\n",
    "        if capitalizeUnigram(word1Cleaned):\n",
    "            resultLine[i] = resultLine[i].capitalize()\n",
    "\n",
    "        if i == 0:\n",
    "            resultLine[i] = resultLine[i].capitalize()\n",
    "\n",
    "   \n",
    "    wordCount += len(line)\n",
    "\n",
    "    wrote = False\n",
    "    for i in range(len(line)):\n",
    "\n",
    "        if line[i].lower() == resultLine[i].lower():\n",
    "            correctWordsCount +=1\n",
    "            if line[i][0] == resultLine[i][0]:\n",
    "                correctWordsCountWithCapitalization += 1\n",
    "\n",
    "dokladnoscPolskawa = correctWordsCount / wordCount\n",
    "dokladnoscPelna = correctWordsCountWithCapitalization / wordCount\n",
    "score = np.sqrt(dokladnoscPelna * dokladnoscPolskawa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9577681695088869\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}